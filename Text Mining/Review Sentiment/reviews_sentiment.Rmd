---
title: "Web Scraping and Sentiment Analysis of Amazon Reviews"
author: "Riki Saito"
date: "August 15, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
pacman::p_load_gh("trinker/sentimentr")
pacman::p_load(XML, dplyr, stringr, rvest, audio)

#Remove all white space
trim <- function (x) gsub("^\\s+|\\s+$", "", x)

#input: html document
amazon_scraper <- function(doc){

  #Remove all white space
  trim <- function (x) gsub("^\\s+|\\s+$", "", x)
  
  title <- doc %>%
    html_nodes("#cm_cr-review_list .a-color-base") %>%
    html_text()
  
  author <- doc %>%
    html_nodes(".review-byline .author") %>%
    html_text()
  
  date <- doc %>%
    html_nodes("#cm_cr-review_list .review-date") %>%
    html_text() %>% 
    gsub(".*on ", "", .)
  
  ver.purchase <- doc%>%
    html_nodes(".review-data.a-spacing-mini") %>%
    html_text() %>%
    grepl("Verified Purchase", .) %>%
    as.numeric()
  
  format <- doc %>% 
    html_nodes(".review-data.a-spacing-mini") %>% 
    html_text() %>%
    gsub("Color: |\\|.*|Verified.*", "", .)
  
  stars <- doc %>%
    html_nodes("#cm_cr-review_list  .review-rating") %>%
    html_text() %>%
    str_extract("\\d") %>%
    as.numeric()
  
  comments <- doc %>%
    html_nodes("#cm_cr-review_list .review-text") %>%
    html_text() 
  
  helpful <- doc %>%
    html_nodes(".cr-vote-buttons .a-color-secondary") %>%
    html_text() %>%
    str_extract("[:digit:]+|One") %>%
    gsub("One", "1", .) %>%
    trim()
  
  df <- data.frame(title, author, date, ver.purchase, format, stars, comments, helpful, stringsAsFactors = F)
  
  return(df)
}
```

Scrape some data

```{r, eval=F}
prod_code = "B0043WCH66"

url <- paste0("https://www.amazon.com/dp/", prod_code)
doc <- read_html(url)

prod <- html_nodes(doc, "#productTitle") %>% html_text() %>% gsub("\n", "", .) %>% trim()
pages <- 10

reviews_all <- NULL
for(page_num in 1:pages){
  url <- paste0("http://www.amazon.com/product-reviews/",prod_code,"/?pageNumber=", page_num)
  doc <- read_html(url)
  
  reviews <- amazon_scraper(doc)
  reviews_all <- rbind(reviews_all, cbind(prod, reviews))
  wait(2)
}
```

```{r, echo = F}
reviews_all = read.csv("C:/Users/rjsai/Documents/reviews.csv", stringsAsFactors = F)
str(reviews_all)
```


sentiment aggregated

```{r}
sent_agg <- with(reviews_all, sentiment_by(comments)) 
head(sent_agg)
```

distribution of sentiment

```{r}
with(sent_agg, hist(ave_sentiment))
```

best

```{r, eval = F}
best_reviews <- slice(reviews_all, top_n(sent_agg, 3, ave_sentiment)$element_id)
with(best_reviews, sentiment_by(comments)) %>% highlight()
```

![](C:\Users\rjsai\Dropbox\Data Science\Just-R-Things\Text Mining\Review Sentiment\positive_reviews.png)

worst 

```{r, eval = F}
worst_reviews <- slice(reviews_all, top_n(sent_agg, 3, -ave_sentiment)$element_id)
with(worst_reviews, sentiment_by(comments)) %>% highlight()
```

![](C:\Users\rjsai\Dropbox\Data Science\Just-R-Things\Text Mining\Review Sentiment\negative_reviews.png)
